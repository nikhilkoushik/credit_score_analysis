# -*- coding: utf-8 -*-
"""Credit_score_analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13N_UbQx_FnpJLGlI8vh5h5FNgsiV7a0R

You are working as a data scientist in a
global finance company. Over the
years, the company has collected basic
bank details and gathered a lot of
credit-related information. The
management wants to build an
intelligent system to segregate the
people into credit score brackets to
reduce the manual efforts. Given a
personâ€™s credit-related information,
build a machine learning model that
can classify the credit score
Credit score dataset contains 1 lac records with 28 features.
1. Handling missing values
2. Data Cleaning
3. Feature Selection
4. Logistic Regression
5. Decision tree Classifier
6. Hyperparametric Tuning(DT)
7. Random Forest Classifier
8. heatmap
9. histogram
"""

# Importing Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.impute import SimpleImputer
from statsmodels.stats.outliers_influence import variance_inflation_factor
from sklearn.model_selection import GridSearchCV
from joblib import parallel_config

# Loading the Data
data = pd.read_csv('/content/credit_score.csv')
data = data.drop(columns = ['ID', 'Customer_ID', 'SSN', 'Name', 'Type_of_Loan', 'Credit_History_Age'])
data.head()

data.shape
data.info()
data.describe()

# Checking Missing Values
missing_values = data.isnull().sum()
print(missing_values)

# Data Cleaning
# Replacing special characters and converting data types
data.replace(['?', '-', '_'], np.nan, inplace=True)
data = data.apply(pd.to_numeric, errors='ignore')

# Data Cleaning - Corrected Code
# Convert to string first to safely apply .str methods
data['Age'] = data['Age'].astype(str).str.replace('_', '')
data['Age'] = pd.to_numeric(data['Age'], errors='coerce')  # Convert back to numeric, handle errors
data['Occupation'] = data['Occupation'].replace('______', np.nan)
data['Annual_Income'] = data['Annual_Income'].astype(str).str.replace('_', '')
data['Annual_Income'] = pd.to_numeric(data['Annual_Income'], errors='coerce')
data['Num_of_Loan'] = data['Num_of_Loan'].astype(str).str.replace('-', '')
data['Num_of_Loan'] = pd.to_numeric(data['Num_of_Loan'], errors='coerce')
data['Num_of_Delayed_Payment'] = data['Num_of_Delayed_Payment'].astype(str).str.replace('-', '')
data['Num_of_Delayed_Payment'] = pd.to_numeric(data['Num_of_Delayed_Payment'], errors='coerce')
data['Credit_Score'] = data['Credit_Score'].replace(['Poor', 'Standard', 'Good'], [0, 1, 2])
data['Monthly_Balance'] = data['Monthly_Balance'].astype(str).str.replace('_', '')
data['Monthly_Balance'] = pd.to_numeric(data['Monthly_Balance'], errors='coerce')
data['Payment_Behaviour'] = data['Payment_Behaviour'].replace('!@9#%8', np.nan)
data['Amount_invested_monthly'] = data['Amount_invested_monthly'].astype(str).str.replace('_', '')
data['Amount_invested_monthly'] = pd.to_numeric(data['Amount_invested_monthly'], errors='coerce')
data['Payment_of_Min_Amount'] = data['Payment_of_Min_Amount'].replace('NM', 'No')
data['Payment_of_Min_Amount'] = data['Payment_of_Min_Amount'].replace(['Yes', 'No'], [1, 0])
data['Outstanding_Debt'] = data['Outstanding_Debt'].astype(str).str.replace('_', '')
data['Outstanding_Debt'] = pd.to_numeric(data['Outstanding_Debt'], errors='coerce')
data['Credit_Mix'] = data['Credit_Mix'].replace('_', np.nan)
data['Credit_Mix'] = data['Credit_Mix'].replace(['Standard', 'Good', 'Bad'], [1, 2, 0])
data['Changed_Credit_Limit'] = data['Changed_Credit_Limit'].astype(str).str.replace('_', '', regex=True)
data['Changed_Credit_Limit'].replace('', np.nan, inplace=True)
data['Changed_Credit_Limit'] = pd.to_numeric(data['Changed_Credit_Limit'], errors='coerce')

data.isnull().sum()
data = data.fillna(method='ffill')
data = data.fillna(method='bfill')
data.isnull().sum()

data.info()
print(missing_values)

sns.boxplot(x=data['Age'])
data = data[(data['Age'] >= 18) & (data['Age'] <= 100)]

# Removing Outliers using IQR method
Q1 = data['Age'].quantile(0.25)
Q3 = data['Age'].quantile(0.75)
IQR = Q3 - Q1
data = data[(data['Age'] >= Q1 - 1.5 * IQR) & (data['Age'] <= Q3 + 1.5 * IQR)]

# Boxplot for Age
plt.figure(figsize=(8, 5))
sns.boxplot(y=data['Age'])
plt.xlabel("Age")
plt.ylabel("Values")
plt.title("Boxplot of Age")
plt.show()

from sklearn.preprocessing import LabelEncoder
le= LabelEncoder()
data["Month"]=le.fit_transform(data["Month"])
data["Occupation"]=le.fit_transform(data["Occupation"])
data["Payment_Behaviour"]=le.fit_transform(data["Payment_Behaviour"])
data.info()

def calculate_vif(df):
    vif_data = pd.DataFrame()
    vif_data['Feature'] = df.columns
    vif_data['VIF'] = [variance_inflation_factor(df.values, i) for i in range(df.shape[1])]
    return vif_data

vif_result = calculate_vif(data.drop('Credit_Score', axis=1))
print(vif_result)

# Splitting Data
X = data.drop('Credit_Score', axis=1)
y = data['Credit_Score']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Logistic Regression
log_reg = LogisticRegression(max_iter=1000)
log_reg.fit(X_train, y_train)
y_pred_lr = log_reg.predict(X_test)
print('Logistic Regression Accuracy:', accuracy_score(y_test, y_pred_lr))
print(classification_report(y_test, y_pred_lr))

# Decision Tree
dt = DecisionTreeClassifier()
dt.fit(X_train, y_train)
y_pred_dt = dt.predict(X_test)
print('Decision Tree Accuracy:', accuracy_score(y_test, y_pred_dt))
print(classification_report(y_test, y_pred_dt))

# Hyperparameter Tuning (Decision Tree)
param_grid = {'max_depth': [3, 5, 10, None], 'min_samples_split': [2, 5, 10]}
grid_search = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=5)
grid_search.fit(X_train, y_train)
print('Best Parameters:', grid_search.best_params_)
y_pred_gs = grid_search.predict(X_test)
print('Tuned Decision Tree Accuracy:', accuracy_score(y_test, y_pred_gs))
print(classification_report(y_test, y_pred_gs))

# Random Forest
rf = RandomForestClassifier(n_estimators=100)
rf.fit(X_train, y_train)
y_pred_rf = rf.predict(X_test)
print('Random Forest Accuracy:', accuracy_score(y_test, y_pred_rf))
print(classification_report(y_test, y_pred_rf))

plt.figure(figsize=(6, 4))
cm = confusion_matrix(y_test, y_pred_rf)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Poor', 'Standard', 'Good'], yticklabels=['Poor', 'Standard', 'Good'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix for Credit Score Classification')
plt.show()

# Data Visualization
plt.figure(figsize=(20,10))
sns.heatmap(data.corr(), annot=True, cmap='coolwarm')
plt.title('Feature Correlation Matrix')
plt.show()

sns.histplot(data['Credit_Score'], kde=True)
plt.title('Credit Score Distribution')
plt.show()